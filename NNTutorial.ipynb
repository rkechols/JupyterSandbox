{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import copy\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def argmax_tensor(t: torch.Tensor):\n",
    "\treturn torch.argmax(t).item()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "def read_32bit_uint(file):\n",
    "\treturn int.from_bytes(file.read(4), \"big\", signed=False)\n",
    "\n",
    "def read_byte_uint(file):\n",
    "\treturn int.from_bytes(file.read(1), \"big\", signed=False)\n",
    "\n",
    "# load MNIST data\n",
    "def load_mnist(images_filename, labels_filename):\n",
    "\timages = list()\n",
    "\trows = 0\n",
    "\tcols = 0\n",
    "\twith open(images_filename, 'rb') as file:\n",
    "\t\tmagic_number = read_32bit_uint(file)\n",
    "\t\tnumber_images = read_32bit_uint(file)\n",
    "\t\trows = read_32bit_uint(file)\n",
    "\t\tcols = read_32bit_uint(file)\n",
    "\t\tfor image_index in range(number_images):\n",
    "\t\t\timage = torch.empty([rows, cols])\n",
    "\t\t\tfor row_index in range(rows):\n",
    "\t\t\t\tfor col_index in range(cols):\n",
    "\t\t\t\t\timage[row_index, col_index] = 255 - read_byte_uint(file)\n",
    "\t\t\timages.append(image)\n",
    "\t\n",
    "\tlabels = list()\n",
    "\tlabel_options = set()\n",
    "\twith open(labels_filename, 'rb') as file:\n",
    "\t\tmagic_number = read_32bit_uint(file)\n",
    "\t\tnumber_labels = read_32bit_uint(file)\n",
    "\t\tfor label_index in range(number_labels):\n",
    "\t\t\tthis_label = read_byte_uint(file)\n",
    "\t\t\tlabels.append(this_label)\n",
    "\t\t\tlabel_options.add(this_label)\n",
    "\tlabel_options = list(label_options)\n",
    "\t\n",
    "\treturn [(images[i], labels[i]) for i in range(len(images))], (rows, cols), label_options\n",
    "\t\n",
    "time_load_start = time.time()\n",
    "mnist_training, training_dimensions, training_label_options = load_mnist(\"mnist/training/train-images.idx3-ubyte\", \"mnist/training/train-labels.idx1-ubyte\")\n",
    "mnist_test, test_dimensions, test_label_options = load_mnist(\"mnist/test/t10k-images.idx3-ubyte\", \"mnist/test/t10k-labels.idx1-ubyte\")\n",
    "time_load_end = time.time()\n",
    "print(\"Loaded MNIST data in\", time_load_end - time_load_start, \"seconds\")\n",
    "\n",
    "# construct a dictionary from label value to index in training_label_options\n",
    "label_to_index = dict()\n",
    "for index, label_value in enumerate(training_label_options):\n",
    "\tlabel_to_index[label_value] = index\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# verify data\n",
    "if training_dimensions != test_dimensions:\n",
    "\tprint(\"WARNING: training data dimensions and test data dimensions do not match!\")\n",
    "\tprint(\"training dimensions:\", training_dimensions)\n",
    "\tprint(\"test dimensions:\", test_dimensions)\n",
    "else:\n",
    "\tprint(\"input dimensions:\", training_dimensions)\n",
    "if training_label_options != test_label_options:\n",
    "\tprint(\"WARNING: training data labels and test data labels do not match!\")\n",
    "\tprint(\"training labels:\", training_label_options)\n",
    "\tprint(\"test labels:\", test_label_options)\n",
    "else:\n",
    "\tprint(\"available labels:\", test_label_options)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# define my generic simple net class\n",
    "class SimpleNet(nn.Module):\n",
    "\tdef __init__(self, input_size, hidden_layer_size, output_size):\n",
    "\t\tsuper(SimpleNet, self).__init__()\n",
    "\t\t# save the meta-parameters\n",
    "\t\tself.input_size = input_size\n",
    "\t\tself.hidden_layer_size = hidden_layer_size\n",
    "\t\tself.output_size = output_size\n",
    "\t\tself.hidden_layers_count = 2\n",
    "\t\t# figure out if we can use a GPU\n",
    "\t\tif torch.cuda.is_available():\n",
    "\t\t\tself.device = torch.device(\"cuda\")\n",
    "\t\telse:\n",
    "\t\t\tself.device = None\n",
    "\t\t# create layer transitions\n",
    "\t\tself.layer_input_to_1 = nn.Linear(self.input_size, self.hidden_layer_size, True)\n",
    "\t\tself.layer_1_to_2 = nn.Linear(self.hidden_layer_size, self.hidden_layer_size, True)\n",
    "\t\tself.layer_2_to_output = nn.Linear(self.hidden_layer_size, self.output_size, True)\n",
    "\t\t# move transition layers to GPU if we can\n",
    "\t\tif not self.device is None:\n",
    "\t\t\tself.layer_input_to_1 = self.layer_input_to_1.cuda()\n",
    "\t\t\tself.layer_1_to_2 = self.layer_1_to_2.cuda()\n",
    "\t\t\tself.layer_2_to_output = self.layer_2_to_output.cuda()\n",
    " \n",
    "\tdef forward(self, x: torch.Tensor):\n",
    "\t\tif not self.device is None:\n",
    "\t\t\tx = x.to(self.device)\n",
    "\t\tx = f.relu(self.layer_input_to_1(x))\n",
    "\t\tx = f.relu(self.layer_1_to_2(x))\n",
    "\t\tx = f.relu(self.layer_2_to_output(x))\n",
    "\t\treturn x\n",
    "\t\n",
    "\t\n",
    "def forward_grayscale_image(net, image: torch.Tensor):\n",
    "\tx = image.view([1, -1])\n",
    "\treturn net.forward(x)\n",
    "\n",
    "# function to test accuracy on a dataset\n",
    "def calculate_accuracy(net, test_data):\n",
    "\ttotal_count = len(test_data)\n",
    "\tif total_count == 0:\n",
    "\t\tprint(\"no data to test\")\n",
    "\t\treturn 0\n",
    "\tcorrect = 0\n",
    "\tfor input_image, correct_output in test_data:\n",
    "\t\tcorrect_label = argmax_tensor(correct_output)\n",
    "\t\tactual_output = forward_grayscale_image(net, input_image)\n",
    "\t\tactual_label = training_label_options[argmax_tensor(actual_output)]\n",
    "\t\tif actual_label == correct_label:\n",
    "\t\t\tcorrect += 1\n",
    "\treturn correct / total_count\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# construct an instance\n",
    "linear_input_size = 1\n",
    "for dimension_size in training_dimensions:\n",
    "\tlinear_input_size *= dimension_size\n",
    "net_MNIST = SimpleNet(linear_input_size, 30, len(training_label_options))\n",
    "# TODO\n",
    "# net_MNIST = nn.Sequential(torch.nn.Linear(linear_input_size, 30),\n",
    "#     torch.nn.ReLU(),\n",
    "#     torch.nn.Linear(30, len(training_label_options)))\n",
    "print(net_MNIST)\n",
    "params = list(net_MNIST.parameters())\n",
    "print(len(params))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# show one of the images to test if we've loaded MNIST data\n",
    "test_image, test_label = mnist_training[0]\n",
    "# convert the image to floats\n",
    "test_image = test_image.float()\n",
    "plt.imshow(test_image, cmap=\"gray\", vmin=0, vmax=255)\n",
    "# show how many data we have\n",
    "print(\"# of training data:\", len(mnist_training))\n",
    "print(\"# of testing data:\", len(mnist_test))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# re-shape the images into vectors\n",
    "\n",
    "def label_to_vector(label: int):\n",
    "\ttarget_vector = torch.zeros([1, len(training_label_options)])\n",
    "\ttarget_vector[0, label_to_index[label]] = 1.0\n",
    "\treturn target_vector\n",
    "\n",
    "mnist_training_vectors = [(image.view([1, -1]), label_to_vector(label)) for image, label in mnist_training]\n",
    "mnist_test_vectors = [(image.view([1, -1]), label_to_vector(label)) for image, label in mnist_test]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "inputs_tensor dimensions: torch.Size([54000, 1, 784])\n",
      "outputs_tensor dimensions: torch.Size([54000, 1, 10])\n",
      "Params equal?\n",
      "True\n",
      "verification_accuracy_current: 0.11133333333333334\n",
      "Params equal?\n",
      "True\n",
      "verification_accuracy_current: 0.11133333333333334\n",
      "Params equal?\n",
      "True\n",
      "verification_accuracy_current: 0.11133333333333334\n",
      "Params equal?\n",
      "True\n",
      "verification_accuracy_current: 0.11133333333333334\n",
      "Params equal?\n",
      "True\n",
      "verification_accuracy_current: 0.11133333333333334\n",
      "Params equal?\n",
      "True\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-fec90d6dd031>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0mLEARNING_RATE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_MNIST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnist_training_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-106-fec90d6dd031>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, full_training_data, learning_rate, batch_size)\u001b[0m\n\u001b[1;32m     79\u001b[0m                                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_after\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mparams_before\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0mverification_accuracy_previous\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverification_accuracy_current\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0mverification_accuracy_current\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverification_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m                 \u001b[0;31m# save accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_training_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-94-51d3e503b476>\u001b[0m in \u001b[0;36mcalculate_accuracy\u001b[0;34m(net, test_data)\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0mcorrect_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margmax_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mactual_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_grayscale_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0mactual_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_label_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margmax_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mactual_label\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcorrect_label\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                         \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-50f0033034b4>\u001b[0m in \u001b[0;36margmax_tensor\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0margmax_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error"
    }
   ],
   "source": [
    "# train the net\n",
    "\n",
    "# def label_to_vector_batch(label_batch):\n",
    "# \treturn torch.stack([label_to_vector(label) for label in label_batch])\n",
    "# \n",
    "# def create_batches(training_data, minimum_batch_size):\n",
    "# \tdata_count = len(training_data)\n",
    "# \tnumber_of_batches = data_count // minimum_batch_size\n",
    "# \tbatches = [list() for i in range(number_of_batches)]\n",
    "# \tunused_datum_indices = set(range(data_count))\n",
    "# \tbatch_index = 0\n",
    "# \twhile len(unused_datum_indices) > 0:\n",
    "# \t\tchosen_index = unused_datum_indices.pop()\n",
    "# \t\tbatches[batch_index].append(training_data[chosen_index])\n",
    "# \t\tbatch_index += 1\n",
    "# \t\tbatch_index %= number_of_batches\n",
    "# \treturn batches\n",
    "\n",
    "class SimpleCustomBatch:\n",
    "    def __init__(self, data):\n",
    "        transposed_data = list(zip(*data))\n",
    "        self.input = torch.stack(transposed_data[0], 0)\n",
    "        self.target = torch.stack(transposed_data[1], 0)\n",
    "\n",
    "    def pin_memory(self):\n",
    "        self.input = self.input.pin_memory()\n",
    "        self.target = self.target.pin_memory()\n",
    "        return self\n",
    "\n",
    "def collate_wrapper(batch_data):\n",
    "    return SimpleCustomBatch(batch_data)\n",
    "\n",
    "def train(net, full_training_data, learning_rate, batch_size):\n",
    "\t# split training data into training and verification\n",
    "\tsplit_index = int(len(full_training_data) * 0.9)\n",
    "\ttraining_data = full_training_data[:split_index]\n",
    "\tverification_data = full_training_data[split_index:]\n",
    "\t# make a place to record accuracy\n",
    "\tdomain = list()\n",
    "\taccuracy_values = list()\n",
    "\t# build some random things we need...\n",
    "\ttime_training_start = time.time()\n",
    "\toptimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\tloss_function = nn.MSELoss(reduction=\"sum\")\n",
    "\tinputs_tensor = torch.stack([datum[0] for datum in training_data], dim=0)\n",
    "\toutputs_tensor = torch.stack([datum[1] for datum in training_data], dim=0)\n",
    "\tprint(\"inputs_tensor dimensions:\", inputs_tensor.size())\n",
    "\tprint(\"outputs_tensor dimensions:\", outputs_tensor.size())\n",
    "\tdataset = TensorDataset(inputs_tensor, outputs_tensor)\n",
    "\tloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_wrapper, pin_memory=True)\n",
    "\t# ensures the next loop runs at least once\n",
    "\tverification_accuracy_previous = -1.0\n",
    "\tverification_accuracy_current = calculate_accuracy(net, verification_data)\n",
    "\t# save accuracy\n",
    "\tdomain.append(time.time() - time_training_start)\n",
    "\taccuracy_values.append(verification_accuracy_current)\n",
    "\t# train until the verification accuracy goes down by more than a specified margin\n",
    "\twhile verification_accuracy_current - verification_accuracy_previous > -0.005:\n",
    "\t\tfirst_batch = True\n",
    "\t\tfor batch in loader:\n",
    "\t\t\tbatch_tensor_input = batch.input\n",
    "\t\t\tbatch_tensor_target = batch.target\n",
    "\t\t\tif not net.device is None:\n",
    "\t\t\t\tbatch_tensor_target = batch_tensor_target.to(net.device)\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\toutput = net(batch_tensor_input)\n",
    "\t\t\tloss = loss_function(output, batch_tensor_target)\n",
    "\t\t\t# if first_batch:\n",
    "\t\t\t# \tfirst_batch = False\n",
    "\t\t\t# \tprint(loss.item())\n",
    "\t\t\tloss.backward()\n",
    "\t\t\tparams_before = copy.copy(list(net.parameters()))\n",
    "\t\t\toptimizer.step()\n",
    "\t\t\tparams_after = copy.copy(list(net.parameters()))\n",
    "\t\t\tif first_batch:\n",
    "\t\t\t\tfirst_batch = False\n",
    "\t\t\t\tprint(\"Params equal?\")\n",
    "\t\t\t\tprint(params_after == params_before)\n",
    "\t\tverification_accuracy_previous = verification_accuracy_current\n",
    "\t\tverification_accuracy_current = calculate_accuracy(net, verification_data)\n",
    "\t\t# save accuracy\n",
    "\t\tdomain.append(time.time() - time_training_start)\n",
    "\t\taccuracy_values.append(verification_accuracy_current)\n",
    "\t\tprint(\"verification_accuracy_current:\", verification_accuracy_current)\n",
    "\t# plot the accuracy over time\n",
    "\tplt.plot(domain, accuracy_values)\n",
    "\tplt.xlabel(\"time elapsed (s)\")\n",
    "\tplt.ylabel(\"accuracy\")\n",
    "\tplt.show()\n",
    "\n",
    "LEARNING_RATE = 0.01\n",
    "train(net_MNIST, mnist_training_vectors, LEARNING_RATE, 200)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# run some tests\n",
    "final_accuracy = calculate_accuracy(net_MNIST, mnist_test_vectors)\n",
    "print(\"final accuracy:\", final_accuracy)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}