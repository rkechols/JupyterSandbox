{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import copy\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def argmax_tensor(t: torch.Tensor):\n",
    "\treturn torch.argmax(t).item()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "def read_32bit_uint(file):\n",
    "\treturn int.from_bytes(file.read(4), \"big\", signed=False)\n",
    "\n",
    "def read_byte_uint(file):\n",
    "\treturn int.from_bytes(file.read(1), \"big\", signed=False)\n",
    "\n",
    "# load MNIST data\n",
    "def load_mnist(images_filename, labels_filename):\n",
    "\timages = list()\n",
    "\trows = 0\n",
    "\tcols = 0\n",
    "\twith open(images_filename, 'rb') as file:\n",
    "\t\tmagic_number = read_32bit_uint(file)\n",
    "\t\tnumber_images = read_32bit_uint(file)\n",
    "\t\trows = read_32bit_uint(file)\n",
    "\t\tcols = read_32bit_uint(file)\n",
    "\t\tfor image_index in range(number_images):\n",
    "\t\t\timage = torch.empty([rows, cols])\n",
    "\t\t\tfor row_index in range(rows):\n",
    "\t\t\t\tfor col_index in range(cols):\n",
    "\t\t\t\t\timage[row_index, col_index] = 255 - read_byte_uint(file)\n",
    "\t\t\timages.append(image)\n",
    "\t\n",
    "\tlabels = list()\n",
    "\tlabel_options = set()\n",
    "\twith open(labels_filename, 'rb') as file:\n",
    "\t\tmagic_number = read_32bit_uint(file)\n",
    "\t\tnumber_labels = read_32bit_uint(file)\n",
    "\t\tfor label_index in range(number_labels):\n",
    "\t\t\tthis_label = read_byte_uint(file)\n",
    "\t\t\tlabels.append(this_label)\n",
    "\t\t\tlabel_options.add(this_label)\n",
    "\tlabel_options = list(label_options)\n",
    "\t\n",
    "\treturn [(images[i], labels[i]) for i in range(len(images))], (rows, cols), label_options\n",
    "\t\n",
    "time_load_start = time.time()\n",
    "mnist_training, training_dimensions, training_label_options = load_mnist(\"mnist/training/train-images.idx3-ubyte\", \"mnist/training/train-labels.idx1-ubyte\")\n",
    "mnist_test, test_dimensions, test_label_options = load_mnist(\"mnist/test/t10k-images.idx3-ubyte\", \"mnist/test/t10k-labels.idx1-ubyte\")\n",
    "time_load_end = time.time()\n",
    "print(\"Loaded MNIST data in\", time_load_end - time_load_start, \"seconds\")\n",
    "\n",
    "# construct a dictionary from label value to index in training_label_options\n",
    "label_to_index = dict()\n",
    "for index, label_value in enumerate(training_label_options):\n",
    "\tlabel_to_index[label_value] = index\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "input dimensions: (28, 28)\n",
      "available labels: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# verify data\n",
    "if training_dimensions != test_dimensions:\n",
    "\tprint(\"WARNING: training data dimensions and test data dimensions do not match!\")\n",
    "\tprint(\"training dimensions:\", training_dimensions)\n",
    "\tprint(\"test dimensions:\", test_dimensions)\n",
    "else:\n",
    "\tprint(\"input dimensions:\", training_dimensions)\n",
    "if training_label_options != test_label_options:\n",
    "\tprint(\"WARNING: training data labels and test data labels do not match!\")\n",
    "\tprint(\"training labels:\", training_label_options)\n",
    "\tprint(\"test labels:\", test_label_options)\n",
    "else:\n",
    "\tprint(\"available labels:\", test_label_options)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [],
   "source": [
    "# define my generic simple net class\n",
    "class SimpleNet(nn.Module):\n",
    "\tdef __init__(self, input_size, hidden_layer_size, output_size):\n",
    "\t\tsuper(SimpleNet, self).__init__()\n",
    "\t\t# save the meta-parameters\n",
    "\t\tself.input_size = input_size\n",
    "\t\tself.hidden_layer_size = hidden_layer_size\n",
    "\t\tself.output_size = output_size\n",
    "\t\tself.hidden_layers_count = 2\n",
    "\t\t# figure out if we can use a GPU\n",
    "\t\tif torch.cuda.is_available():\n",
    "\t\t\tself.device = torch.device(\"cuda\")\n",
    "\t\telse:\n",
    "\t\t\tself.device = None\n",
    "\t\t# create layer transitions\n",
    "\t\tself.layer_input_to_1 = nn.Parameter(torch.ones([self.hidden_layer_size, self.input_size], requires_grad=True).cuda(), True)\n",
    "\t\tself.layer_1_to_2 = nn.Parameter(torch.ones([self.hidden_layer_size, self.hidden_layer_size], requires_grad=True).cuda(), True)\n",
    "\t\tself.layer_2_to_output = nn.Parameter(torch.ones([self.output_size, self.hidden_layer_size], requires_grad=True).cuda(), True)\n",
    "\t\t# move transition layers to GPU if we can\n",
    "\t\t# if not self.device is None:\n",
    "\t\t# \tself.layer_input_to_1 = self.layer_input_to_1.cuda()\n",
    "\t\t# \tself.layer_1_to_2 = self.layer_1_to_2.cuda()\n",
    "\t\t# \tself.layer_2_to_output = self.layer_2_to_output.cuda()\n",
    " \n",
    "\tdef forward(self, x: torch.Tensor):\n",
    "\t\tif not self.device is None:\n",
    "\t\t\tx = x.to(self.device)\n",
    "\t\tx = f.relu(self.layer_input_to_1.matmul(x))\n",
    "\t\tx = f.relu(self.layer_1_to_2.matmul(x))\n",
    "\t\tx = f.relu(self.layer_2_to_output.matmul(x))\n",
    "\t\treturn x\n",
    "\t\n",
    "\t\n",
    "def forward_grayscale_image(net, image: torch.Tensor):\n",
    "\tx = image.view([-1])\n",
    "\treturn net.forward(x)\n",
    "\n",
    "# function to test accuracy on a dataset\n",
    "def calculate_accuracy(net, test_data):\n",
    "\ttotal_count = len(test_data)\n",
    "\tif total_count == 0:\n",
    "\t\tprint(\"no data to test\")\n",
    "\t\treturn 0\n",
    "\tcorrect = 0\n",
    "\tfor input_image, correct_output in test_data:\n",
    "\t\tcorrect_label = argmax_tensor(correct_output)\n",
    "\t\tactual_output = forward_grayscale_image(net, input_image)\n",
    "\t\tactual_label = training_label_options[argmax_tensor(actual_output)]\n",
    "\t\tif actual_label == correct_label:\n",
    "\t\t\tcorrect += 1\n",
    "\treturn correct / total_count\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "SimpleNet()\n",
      "3\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# construct an instance\n",
    "linear_input_size = 1\n",
    "for dimension_size in training_dimensions:\n",
    "\tlinear_input_size *= dimension_size\n",
    "net_MNIST = SimpleNet(linear_input_size, 30, len(training_label_options))\n",
    "# TODO\n",
    "# net_MNIST = nn.Sequential(torch.nn.Linear(linear_input_size, 30),\n",
    "#     torch.nn.ReLU(),\n",
    "#     torch.nn.Linear(30, len(training_label_options)))\n",
    "print(net_MNIST)\n",
    "params = list(net_MNIST.parameters())\n",
    "print(len(params))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "# of training data: 60000\n",
      "# of testing data: 10000\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<matplotlib.figure.Figure at 0x7fb9c5b58c88>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show one of the images to test if we've loaded MNIST data\n",
    "test_image, test_label = mnist_training[0]\n",
    "# convert the image to floats\n",
    "test_image = test_image.float()\n",
    "plt.imshow(test_image, cmap=\"gray\", vmin=0, vmax=255)\n",
    "# show how many data we have\n",
    "print(\"# of training data:\", len(mnist_training))\n",
    "print(\"# of testing data:\", len(mnist_test))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [],
   "source": [
    "# re-shape the images into vectors\n",
    "\n",
    "def label_to_vector(label: int):\n",
    "\ttarget_vector = torch.zeros([len(training_label_options)])\n",
    "\ttarget_vector[label_to_index[label]] = 1.0\n",
    "\treturn target_vector\n",
    "\n",
    "mnist_training_vectors = [(image.view([-1]), label_to_vector(label)) for image, label in mnist_training]\n",
    "mnist_test_vectors = [(image.view([-1]), label_to_vector(label)) for image, label in mnist_test]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "inputs_tensor dimensions: torch.Size([54000, 784])\n",
      "outputs_tensor dimensions: torch.Size([54000, 10])\n",
      "max_diff: 0.0\n",
      "verification_accuracy_current: 0.11133333333333334\n",
      "max_diff: 0.0\n",
      "verification_accuracy_current: 0.11133333333333334\n",
      "max_diff: 0.0\n",
      "verification_accuracy_current: 0.11133333333333334\n",
      "max_diff: 0.0\n",
      "verification_accuracy_current: 0.11133333333333334\n",
      "max_diff: 0.0\n",
      "verification_accuracy_current: 0.11133333333333334\n",
      "max_diff: 0.0\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-178-25a1d86e5c3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0mLEARNING_RATE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_MNIST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnist_training_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-178-25a1d86e5c3e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, full_training_data, learning_rate, batch_size)\u001b[0m\n\u001b[1;32m     84\u001b[0m                                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"max_diff:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_diff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0mverification_accuracy_previous\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverification_accuracy_current\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                 \u001b[0mverification_accuracy_current\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverification_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m                 \u001b[0;31m# save accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_training_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-163-ef8250ef2003>\u001b[0m in \u001b[0;36mcalculate_accuracy\u001b[0;34m(net, test_data)\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0mcorrect_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margmax_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mactual_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_grayscale_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0mactual_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_label_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margmax_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mactual_label\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcorrect_label\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                         \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-50f0033034b4>\u001b[0m in \u001b[0;36margmax_tensor\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0margmax_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error"
    }
   ],
   "source": [
    "# train the net\n",
    "\n",
    "# def label_to_vector_batch(label_batch):\n",
    "# \treturn torch.stack([label_to_vector(label) for label in label_batch])\n",
    "# \n",
    "# def create_batches(training_data, minimum_batch_size):\n",
    "# \tdata_count = len(training_data)\n",
    "# \tnumber_of_batches = data_count // minimum_batch_size\n",
    "# \tbatches = [list() for i in range(number_of_batches)]\n",
    "# \tunused_datum_indices = set(range(data_count))\n",
    "# \tbatch_index = 0\n",
    "# \twhile len(unused_datum_indices) > 0:\n",
    "# \t\tchosen_index = unused_datum_indices.pop()\n",
    "# \t\tbatches[batch_index].append(training_data[chosen_index])\n",
    "# \t\tbatch_index += 1\n",
    "# \t\tbatch_index %= number_of_batches\n",
    "# \treturn batches\n",
    "\n",
    "class SimpleCustomBatch:\n",
    "    def __init__(self, data):\n",
    "        transposed_data = list(zip(*data))\n",
    "        self.input = torch.stack(transposed_data[0], 0)\n",
    "        self.target = torch.stack(transposed_data[1], 0)\n",
    "\n",
    "    def pin_memory(self):\n",
    "        self.input = self.input.pin_memory()\n",
    "        self.target = self.target.pin_memory()\n",
    "        return self\n",
    "\n",
    "def collate_wrapper(batch_data):\n",
    "    return SimpleCustomBatch(batch_data)\n",
    "\n",
    "def train(net, full_training_data, learning_rate, batch_size):\n",
    "\t# split training data into training and verification\n",
    "\tsplit_index = int(len(full_training_data) * 0.9)\n",
    "\ttraining_data = full_training_data[:split_index]\n",
    "\tverification_data = full_training_data[split_index:]\n",
    "\t# make a place to record accuracy\n",
    "\tdomain = list()\n",
    "\taccuracy_values = list()\n",
    "\t# build some random things we need...\n",
    "\ttime_training_start = time.time()\n",
    "\toptimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\tloss_function = nn.MSELoss(reduction=\"sum\")\n",
    "\tinputs_tensor = torch.stack([datum[0] for datum in training_data], dim=0)\n",
    "\toutputs_tensor = torch.stack([datum[1] for datum in training_data], dim=0)\n",
    "\tprint(\"inputs_tensor dimensions:\", inputs_tensor.size())\n",
    "\tprint(\"outputs_tensor dimensions:\", outputs_tensor.size())\n",
    "\tdataset = TensorDataset(inputs_tensor, outputs_tensor)\n",
    "\tloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_wrapper, pin_memory=True)\n",
    "\t# ensures the next loop runs at least once\n",
    "\tverification_accuracy_previous = -1.0\n",
    "\tverification_accuracy_current = calculate_accuracy(net, verification_data)\n",
    "\t# save accuracy\n",
    "\tdomain.append(time.time() - time_training_start)\n",
    "\taccuracy_values.append(verification_accuracy_current)\n",
    "\t# train until the verification accuracy goes down by more than a specified margin\n",
    "\twhile verification_accuracy_current - verification_accuracy_previous > -0.005:\n",
    "\t\tfirst_batch = True\n",
    "\t\tfor batch in loader:\n",
    "\t\t\tbatch_tensor_input = batch.input.transpose(0, 1)\n",
    "\t\t\tbatch_tensor_target = batch.target.transpose(0, 1)\n",
    "\t\t\tif not net.device is None:\n",
    "\t\t\t\tbatch_tensor_target = batch_tensor_target.to(net.device)\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\toutput = net(batch_tensor_input)\n",
    "\t\t\tloss = loss_function(output, batch_tensor_target)\n",
    "\t\t\t# if first_batch:\n",
    "\t\t\t# \tfirst_batch = False\n",
    "\t\t\t# \tprint(loss.item())\n",
    "\t\t\tloss.backward()\n",
    "\t\t\tparams_before = copy.copy(list(net.parameters()))\n",
    "\t\t\toptimizer.step()\n",
    "\t\t\tparams_after = copy.copy(list(net.parameters()))\n",
    "\t\t\tif first_batch:\n",
    "\t\t\t\tfirst_batch = False\n",
    "\t\t\t\tmax_diff = -1.0\n",
    "\t\t\t\tfor i in range(len(params_after)):\n",
    "\t\t\t\t\tdifference = abs(params_after[i] - params_before[i])\n",
    "\t\t\t\t\tthis_max_diff = max([max([difference[row, col].item() for row in range(difference.shape[0])]) for col in range(difference.shape[1])])\n",
    "\t\t\t\t\tif this_max_diff > max_diff:\n",
    "\t\t\t\t\t\tmax_diff = this_max_diff\n",
    "\t\t\t\tprint(\"max_diff:\", max_diff)\n",
    "\t\tverification_accuracy_previous = verification_accuracy_current\n",
    "\t\tverification_accuracy_current = calculate_accuracy(net, verification_data)\n",
    "\t\t# save accuracy\n",
    "\t\tdomain.append(time.time() - time_training_start)\n",
    "\t\taccuracy_values.append(verification_accuracy_current)\n",
    "\t\tprint(\"verification_accuracy_current:\", verification_accuracy_current)\n",
    "\t# plot the accuracy over time\n",
    "\tplt.plot(domain, accuracy_values)\n",
    "\tplt.xlabel(\"time elapsed (s)\")\n",
    "\tplt.ylabel(\"accuracy\")\n",
    "\tplt.show()\n",
    "\n",
    "LEARNING_RATE = 0.1\n",
    "train(net_MNIST, mnist_training_vectors, LEARNING_RATE, 200)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# run some tests\n",
    "final_accuracy = calculate_accuracy(net_MNIST, mnist_test_vectors)\n",
    "print(\"final accuracy:\", final_accuracy)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}