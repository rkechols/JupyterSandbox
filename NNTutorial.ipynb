{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import copy\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def argmax_tensor(t: torch.Tensor):\n",
    "\treturn torch.argmax(t).item()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded MNIST data in 1029.2017602920532 seconds\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "def read_32bit_uint(file):\n",
    "\treturn int.from_bytes(file.read(4), \"big\", signed=False)\n",
    "\n",
    "def read_byte_uint(file):\n",
    "\treturn int.from_bytes(file.read(1), \"big\", signed=False)\n",
    "\n",
    "# load MNIST data\n",
    "def load_mnist(images_filename, labels_filename):\n",
    "\timages = list()\n",
    "\trows = 0\n",
    "\tcols = 0\n",
    "\twith open(images_filename, 'rb') as file:\n",
    "\t\tmagic_number = read_32bit_uint(file)\n",
    "\t\tnumber_images = read_32bit_uint(file)\n",
    "\t\trows = read_32bit_uint(file)\n",
    "\t\tcols = read_32bit_uint(file)\n",
    "\t\tfor image_index in range(number_images):\n",
    "\t\t\timage = torch.empty([rows, cols])\n",
    "\t\t\tfor row_index in range(rows):\n",
    "\t\t\t\tfor col_index in range(cols):\n",
    "\t\t\t\t\timage[row_index, col_index] = 255 - read_byte_uint(file)\n",
    "\t\t\timages.append(image)\n",
    "\t\n",
    "\tlabels = list()\n",
    "\tlabel_options = set()\n",
    "\twith open(labels_filename, 'rb') as file:\n",
    "\t\tmagic_number = read_32bit_uint(file)\n",
    "\t\tnumber_labels = read_32bit_uint(file)\n",
    "\t\tfor label_index in range(number_labels):\n",
    "\t\t\tthis_label = read_byte_uint(file)\n",
    "\t\t\tlabels.append(this_label)\n",
    "\t\t\tlabel_options.add(this_label)\n",
    "\tlabel_options = list(label_options)\n",
    "\t\n",
    "\treturn [(images[i], labels[i]) for i in range(len(images))], (rows, cols), label_options\n",
    "\t\n",
    "time_load_start = time.time()\n",
    "mnist_training, training_dimensions, training_label_options = load_mnist(\"mnist/training/train-images.idx3-ubyte\", \"mnist/training/train-labels.idx1-ubyte\")\n",
    "mnist_test, test_dimensions, test_label_options = load_mnist(\"mnist/test/t10k-images.idx3-ubyte\", \"mnist/test/t10k-labels.idx1-ubyte\")\n",
    "time_load_end = time.time()\n",
    "print(\"Loaded MNIST data in\", time_load_end - time_load_start, \"seconds\")\n",
    "\n",
    "# construct a dictionary from label value to index in training_label_options\n",
    "label_to_index = dict()\n",
    "for index, label_value in enumerate(training_label_options):\n",
    "\tlabel_to_index[label_value] = index\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input dimensions: (28, 28)\n",
      "available labels: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "# verify data\n",
    "if training_dimensions != test_dimensions:\n",
    "\tprint(\"WARNING: training data dimensions and test data dimensions do not match!\")\n",
    "\tprint(\"training dimensions:\", training_dimensions)\n",
    "\tprint(\"test dimensions:\", test_dimensions)\n",
    "else:\n",
    "\tprint(\"input dimensions:\", training_dimensions)\n",
    "if training_label_options != test_label_options:\n",
    "\tprint(\"WARNING: training data labels and test data labels do not match!\")\n",
    "\tprint(\"training labels:\", training_label_options)\n",
    "\tprint(\"test labels:\", test_label_options)\n",
    "else:\n",
    "\tprint(\"available labels:\", test_label_options)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of training data: 60000\n",
      "# of testing data: 10000\n"
     ]
    },
    {
     "data": {
      "text/plain": "<matplotlib.figure.Figure at 0x7faef40434a8>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show one of the images to test if we've loaded MNIST data\n",
    "test_image, test_label = mnist_training[0]\n",
    "# convert the image to floats\n",
    "test_image = test_image.float()\n",
    "plt.imshow(test_image, cmap=\"gray\", vmin=0, vmax=255)\n",
    "# show how many data we have\n",
    "print(\"# of training data:\", len(mnist_training))\n",
    "print(\"# of testing data:\", len(mnist_test))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# re-shape the images into vectors\n",
    "\n",
    "def label_to_vector(label: int):\n",
    "\ttarget_vector = torch.zeros([len(training_label_options)])\n",
    "\ttarget_vector[label_to_index[label]] = 1.0\n",
    "\treturn target_vector\n",
    "\n",
    "mnist_training_vectors = [(image.view([-1]), label_to_vector(label)) for image, label in mnist_training]\n",
    "mnist_test_vectors = [(image.view([-1]), label_to_vector(label)) for image, label in mnist_test]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "# define my generic simple net class\n",
    "class SimpleNet(nn.Module):\n",
    "\tdef __init__(self, input_size, hidden_layer_size, output_size):\n",
    "\t\tsuper(SimpleNet, self).__init__()\n",
    "\t\t# save the meta-parameters\n",
    "\t\tself.input_size = input_size\n",
    "\t\tself.hidden_layer_size = hidden_layer_size\n",
    "\t\tself.output_size = output_size\n",
    "\t\tself.hidden_layers_count = 2\n",
    "\t\t# create layer transitions\n",
    "\t\tself.layer_input_to_1 = nn.Linear(self.input_size, self.hidden_layer_size, True).cuda()\n",
    "\t\tself.layer_1_to_2 = nn.Linear(self.hidden_layer_size, self.hidden_layer_size, True).cuda()\n",
    "\t\tself.layer_2_to_output = nn.Linear(self.hidden_layer_size, self.output_size, True).cuda()\n",
    " \n",
    "\tdef forward(self, x: torch.Tensor):\n",
    "\t\tx = x.cuda()\n",
    "\t\tx = torch.sigmoid(self.layer_input_to_1(x))\n",
    "\t\tx = torch.sigmoid(self.layer_1_to_2(x))\n",
    "\t\tx = torch.sigmoid(self.layer_2_to_output(x))\n",
    "\t\treturn x\n",
    "\t\n",
    "def forward_grayscale_image(net, image: torch.Tensor):\n",
    "\tx = image.view([-1]).cuda()\n",
    "\treturn net.forward(x)\n",
    "\n",
    "# function to test accuracy on a dataset\n",
    "def calculate_accuracy(net, test_data):\n",
    "\ttotal_count = len(test_data)\n",
    "\tif total_count == 0:\n",
    "\t\tprint(\"no data to test\")\n",
    "\t\treturn 0\n",
    "\tcorrect = 0\n",
    "\tfor input_image, correct_output in test_data:\n",
    "\t\tcorrect_label = argmax_tensor(correct_output)\n",
    "\t\tactual_output = forward_grayscale_image(net, input_image)\n",
    "\t\tactual_label = training_label_options[argmax_tensor(actual_output)]\n",
    "\t\tif actual_label == correct_label:\n",
    "\t\t\tcorrect += 1\n",
    "\treturn correct / total_count\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNet(\n",
      "  (layer_input_to_1): Linear(in_features=784, out_features=30, bias=True)\n",
      "  (layer_1_to_2): Linear(in_features=30, out_features=30, bias=True)\n",
      "  (layer_2_to_output): Linear(in_features=30, out_features=10, bias=True)\n",
      ")\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# construct an instance\n",
    "linear_input_size = 1\n",
    "for dimension_size in training_dimensions:\n",
    "\tlinear_input_size *= dimension_size\n",
    "net_MNIST = SimpleNet(linear_input_size, 30, len(training_label_options))\n",
    "\n",
    "print(net_MNIST)\n",
    "params = list(net_MNIST.parameters())\n",
    "print(len(params))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verification_accuracy_current: 0.1\n",
      "verification_accuracy_current: 0.1\n",
      "verification_accuracy_current: 0.1\n",
      "verification_accuracy_current: 0.1\n",
      "verification_accuracy_current: 0.09916666666666667\n",
      "verification_accuracy_current: 0.0975\n",
      "verification_accuracy_current: 0.0975\n",
      "verification_accuracy_current: 0.0975\n",
      "verification_accuracy_current: 0.0975\n",
      "verification_accuracy_current: 0.0975\n",
      "verification_accuracy_current: 0.0975\n",
      "verification_accuracy_current: 0.0975\n",
      "verification_accuracy_current: 0.0975\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-62-7cdf20cf9e89>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     73\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     74\u001B[0m \u001B[0mLEARNING_RATE\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m1e-2\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 75\u001B[0;31m \u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnet_MNIST\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmnist_training_vectors\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mLEARNING_RATE\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m100\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     76\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     77\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-62-7cdf20cf9e89>\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(model, full_training_data, learning_rate, batch_size)\u001B[0m\n\u001B[1;32m     58\u001B[0m                         \u001B[0;31m# if first_batch:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     59\u001B[0m                         \u001B[0;31m#       print(\"grad:\", list(model.parameters())[0].grad)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 60\u001B[0;31m                         \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     61\u001B[0m                         \u001B[0mfirst_batch\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m                 \u001B[0mverification_accuracy_previous\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mverification_accuracy_current\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/sgd.py\u001B[0m in \u001B[0;36mstep\u001B[0;34m(self, closure)\u001B[0m\n\u001B[1;32m    104\u001B[0m                         \u001B[0md_p\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbuf\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    105\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 106\u001B[0;31m                 \u001B[0mp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0mgroup\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'lr'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0md_p\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    107\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    108\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mloss\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# train the net\n",
    "\n",
    "def training_pairs_to_tensors(list_of_pairs):\n",
    "\tfirst = torch.stack([t[0] for t in list_of_pairs])\n",
    "\tsecond = torch.stack([t[1] for t in list_of_pairs])\n",
    "\treturn first, second\n",
    "\n",
    "def create_batches(training_data, minimum_batch_size):\n",
    "\tdata_count = len(training_data)\n",
    "\tnumber_of_batches = data_count // minimum_batch_size\n",
    "\tbatches = [list() for i in range(number_of_batches)]\n",
    "\tunused_datum_indices = set(range(data_count))\n",
    "\tbatch_index = 0\n",
    "\twhile len(unused_datum_indices) > 0:\n",
    "\t\tchosen_index = unused_datum_indices.pop()\n",
    "\t\tbatches[batch_index].append(training_data[chosen_index])\n",
    "\t\tbatch_index += 1\n",
    "\t\tbatch_index %= number_of_batches\n",
    "\treturn batches\n",
    "\n",
    "def train(model, full_training_data, learning_rate, batch_size):\n",
    "\t# split training data into training and verification\n",
    "\tsplit_index = int(len(full_training_data) * 0.9)\n",
    "\ttraining_data = full_training_data[:split_index]\n",
    "\tverification_data = full_training_data[split_index:]\n",
    "\t# make a place to record accuracy\n",
    "\tdomain = list()\n",
    "\taccuracy_values = list()\n",
    "\t# ensures the next loop runs at least once\n",
    "\tverification_accuracy_previous = -1.0\n",
    "\tverification_accuracy_current = calculate_accuracy(model, verification_data)\n",
    "\t# save accuracy\n",
    "\ttime_training_start = time.time()\n",
    "\tdomain.append(time.time() - time_training_start)\n",
    "\taccuracy_values.append(verification_accuracy_current)\n",
    "\t# make our loss function and optimizer\n",
    "\tcriterion = nn.MSELoss(reduction=\"sum\")\n",
    "\toptimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\t# train until the verification accuracy goes down by more than a specified margin\n",
    "\tepochs = 0\n",
    "\twhile epochs < 30 or verification_accuracy_current - verification_accuracy_previous > -0.005:\n",
    "\t\tepochs += 1\n",
    "\t\t# make batches\n",
    "\t\tbatches = create_batches(training_data, batch_size)\n",
    "\t\t# use the batches for gradient descent\n",
    "\t\tfirst_batch = True\n",
    "\t\tfor batch in batches:\n",
    "\t\t\t# unzip the training data into two huge tensors\n",
    "\t\t\tbatch_inputs_stacked, batch_outputs_stacked = training_pairs_to_tensors(batch)\n",
    "\t\t\tbatch_inputs_stacked = batch_inputs_stacked.cuda()\n",
    "\t\t\tbatch_outputs_stacked = batch_outputs_stacked.cuda()\n",
    "\t\t\t# put the batch through\n",
    "\t\t\toutput = model(batch_inputs_stacked)\n",
    "\t\t\tloss = criterion(output, batch_outputs_stacked)\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\tloss.backward()\n",
    "\t\t\t# if first_batch:\n",
    "\t\t\t# \tprint(\"grad:\", list(model.parameters())[0].grad)\n",
    "\t\t\toptimizer.step()\n",
    "\t\t\tfirst_batch = False\n",
    "\t\tverification_accuracy_previous = verification_accuracy_current\n",
    "\t\tverification_accuracy_current = calculate_accuracy(model, verification_data)\n",
    "\t\t# save accuracy\n",
    "\t\tdomain.append(time.time() - time_training_start)\n",
    "\t\taccuracy_values.append(verification_accuracy_current)\n",
    "\t\tprint(\"verification_accuracy_current:\", verification_accuracy_current)\n",
    "\t# plot the accuracy over time\n",
    "\tplt.plot(domain, accuracy_values)\n",
    "\tplt.xlabel(\"time elapsed (s)\")\n",
    "\tplt.ylabel(\"accuracy\")\n",
    "\tplt.show()\n",
    "\n",
    "LEARNING_RATE = 1e-2\n",
    "train(net_MNIST, mnist_training_vectors, LEARNING_RATE, 100)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# run some tests\n",
    "final_accuracy = calculate_accuracy(net_MNIST, mnist_test_vectors)\n",
    "print(\"final accuracy:\", final_accuracy)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}